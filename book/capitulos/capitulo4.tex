\chapter{Método Propuesto}

Este trabajo propone un sistema de desfragmentación proactiva para redes MC-EON mediante el uso de técnicas de \textit{Machine Learning} \cite{mitchell1997machine}. El sistema predice el índice de fragmentación futuro (\textit{Bandwidth Fragmentation Ratio} o BFR) que experimentará la red y, en función de estos valores predichos, determina automáticamente cuándo y con qué frecuencia ejecutar procesos de desfragmentación.

\section{Estrategia de Desfragmentación Adaptativa}

El sistema implementa una estrategia de tres niveles basada en dos umbrales de fragmentación \cite{zhang2014dynamic}:

\begin{itemize}
    \item \textbf{Umbral mínimo (BFR = 0.20):} Indica el inicio de fragmentación apreciable
    \item \textbf{Umbral crítico (BFR = 0.46):} Señala estados de alta fragmentación que incrementan significativamente la probabilidad de bloqueo
\end{itemize}

La lógica de actuación se define como:

\begin{enumerate}
    \item \textbf{Sin desfragmentación:} Si la predicción indica que el BFR futuro no superará el umbral mínimo (BFR $< 0.20$)
    \item \textbf{Desfragmentación de baja frecuencia:} Si el BFR predicho supera el umbral mínimo pero no alcanza el umbral crítico ($0.20 \leq$ BFR $< 0.46$)
    \item \textbf{Desfragmentación de alta frecuencia:} Si el BFR predicho supera el umbral crítico (BFR $\geq 0.46$)
\end{enumerate}

Esta aproximación permite actuar de manera preventiva antes de que la red alcance estados críticos \cite{comellas2018periodic}, optimizando el balance entre los costos operacionales de la desfragmentación y el mantenimiento de niveles aceptables de fragmentación.

\section{Características Utilizadas}

En el contexto de \textit{Machine Learning}, las características son los parámetros de entrada que alimentan el modelo predictivo. Para este trabajo se seleccionaron métricas relacionadas con la fragmentación, utilización de recursos y comportamiento específico de redes MC-EON \cite{quagliotti2017spectrum}:

\begin{itemize}
    \item \textbf{Bandwidth Fragmentation Ratio (BFR)}: Representa el índice de fragmentación de los recursos de la red \cite{zhang2013bandwidth}. El BFR de un core en un enlace se define como:
    \begin{equation}
        BFR_{core} = 1 - \frac{MaxBlock()}{S^{free}}
    \end{equation}
    donde \textit{MaxBlock()} es el tamaño del mayor bloque de frequency slots (FS) libres y \(S^{free}\) es la suma total de FS libres en el core.
    
    El BFR de la red se calcula como el promedio ponderado considerando todos los cores de todos los enlaces:
    \begin{equation}
       BFR_{red} = 1 - \frac{\sum_{i=1}^{|E|} \sum_{j=1}^{C} MaxBlock_{i,j}}{\sum_{i=1}^{|E|} \sum_{j=1}^{C} S^{free}_{i,j}}
    \end{equation}
    donde \(C\) es el número de cores por enlace, \(MaxBlock_{i,j}\) es el mayor bloque libre en el core \(j\) del enlace \(i\), y \(S^{free}_{i,j}\) es el total de FS libres en ese core.
    
    \item \textbf{Entropía de Shannon (SHF)}: Mide la distribución de bloques libres en el espectro \cite{wright2015minimum}. Para un core:
    \begin{equation}
        SHF_{core} = \sum_{i=1}^{B} \frac{S_{i}^{free}}{N}~\ln\frac{N}{S_{i}^{free}}
    \end{equation}
    donde \(S_{i}^{free}\) es el tamaño del bloque libre \(i\), \(N\) es el número total de FS, y \(B\) es la cantidad de bloques libres. El SHF de la red se calcula como:
    \begin{equation}
        SHF_{red} = \frac{1}{|E| \times C} \sum_{i=1}^{|E|} \sum_{j=1}^{C} SHF_{core_{i,j}}
    \end{equation}
    
    \item \textbf{Compacidad del Espectro (SC)}: Evalúa qué tan compacto está el uso del espectro considerando la dispersión de FS ocupados y la cantidad de gaps intermedios \cite{zhang2012priority}. Para un core:
    \begin{equation}
        SC_{core} = \frac{s_{max} - s_{min} + 1}{S^{occupied}} \times \frac{\sum_{i=1}^{G} g_i}{G}
    \end{equation}
    donde \(s_{min}\) y \(s_{max}\) son los índices del primer y último FS ocupado, \(S^{occupied}\) es la cantidad total de FS ocupados, \(g_i\) es el tamaño del gap libre \(i\), y \(G\) es la cantidad total de gaps. Si no hay FS ocupados, \(SC_{core} = 0\).
    
    \item \textbf{Golden Metric (GM)}: Métrica avanzada que evalúa la fragmentación considerando rangos de tamaño de demandas esperadas \cite{khorasani2018novel}. Dados dos parámetros \(n_1\) y \(n_2\) que representan tamaños típicos de demanda, el GM para un core se calcula como:
    \begin{equation}
        GM_{core} = \frac{a}{|b|}
    \end{equation}
    donde \(a\) y \(b\) se calculan iterando sobre cada gap de FS libres:
    \begin{equation}
        a_0 = \epsilon, \quad b_0 = -\epsilon, \quad a = a_0 + \sum_{i=1}^{G} a_i, \quad b = b_0 + \sum_{i=1}^{G} b_i
    \end{equation}
    con \(\epsilon = 0.001\), y para cada gap \(g_i\):
    \begin{itemize}
        \item Si \(g_i < n_1\): \(a_i = 0\), \(b_i = -\frac{g_i}{avg}\)
        \item Si \(g_i > n_2\): \(a_i = \frac{g_i}{avg}\), \(b_i = 0\)
        \item Si \(n_1 \leq g_i \leq n_2\): \(a_i = \frac{g_i - n_1 + 1}{avg}\), \(b_i = -\frac{n_2 - g_i}{avg}\)
    \end{itemize}
    con \(avg = \frac{n_1 + n_2}{2}\).
    
    \item \textbf{Available Spectrum Fragmentation Ratio 3D (ASFR3D)}: Considera la fragmentación espacial en redes multi-core \cite{zhang2020fragmentation}, evaluando bloques pequeños de difícil utilización:
    \begin{equation}
        ASFR3D_{core} = \left(1 - \frac{S^{small}}{S^{free}}\right) \times F_{spatial}
    \end{equation}
    donde \(S^{small}\) es la suma de FS libres en bloques menores a 5 slots, y \(F_{spatial}\) es un factor de peso espacial:
    \begin{equation}
        F_{spatial} = \frac{\ln(D_{active} + 1)}{10}
    \end{equation}
    siendo \(D_{active}\) el número de demandas activas en la red.
    
    \item \textbf{Utilización Diferencial (UD)}: Mide el desbalance en la utilización entre cores y enlaces. Esta métrica está inspirada en conceptos de balanceo de carga en redes definidas por software \cite{guo2014improving}:
    \begin{equation}
        UD_{red} = U_{max} - U_{min}
    \end{equation}
    donde \(U_{max}\) y \(U_{min}\) son las utilizaciones máxima y mínima entre todos los cores, siendo:
    \begin{equation}
        U_{core} = \frac{S^{occupied}}{N}
    \end{equation}
    Un valor alto de UD indica desbalance en la carga de la red.
\end{itemize}

\section{Generación de Datos de Entrenamiento}

\subsection{Simulador y Topología}

Se utilizó un simulador de redes MC-EON \cite{davalos2019spectrum} para generar el conjunto de datos de entrenamiento. La topología empleada fue USNET, representativa de redes ópticas de producción. Se generaron 400,000 instancias de tráfico, de las cuales 399,000 fueron utilizables para el análisis y entrenamiento tras eliminar valores incompletos.

\subsection{Modelo de Carga Variable}

Para simular condiciones realistas de tráfico, se implementó un modelo matemático de carga temporal que genera patrones cuasiperiódicos con variabilidad controlada. La función de carga \(C(t)\) se define como una combinación de ondas sinusoidales sobre un tiempo normalizado \(t \in [0, 1]\):

\begin{equation}
\begin{split}
C(t) = & \sin(3\pi t) + 0.35\,\sin(7\pi t) + 0.18\,\sin(11\pi t) \\
       & + 0.10\,\sin(15\pi t) + 0.20\,\sin(4\pi t)\cos(2\pi t) \\
       & - 0.25\,\cos(5\pi t) + 0.15\,\sin(\pi t)
\end{split}
\label{eq:funcionCarga}
\end{equation}

Los componentes de esta función tienen roles específicos, como se detalla en la Tabla~\ref{tab:componentes_modelo}:

\begin{table}[H]
\centering
\caption{Componentes del modelo matemático de carga}
\label{tab:componentes_modelo}
\begin{tabular}{lll}
\hline
\textbf{Componente} & \textbf{Expresión} & \textbf{Función} \\
\hline
Principal & $\sin(3\pi t)$ & Ciclo fundamental de carga \\
Armónica 1 & $0.35\,\sin(7\pi t)$ & Primera microfluctuación \\
Armónica 2 & $0.18\,\sin(11\pi t)$ & Segunda microfluctuación \\
Armónica 3 & $0.10\,\sin(15\pi t)$ & Tercera microfluctuación \\
Modulación & $0.20\,\sin(4\pi t)\cos(2\pi t)$ & Interferencia entre patrones \\
Compensación & $-0.25\,\cos(5\pi t)$ & Asimetrías y prolongación de fases \\
Tendencia & $0.15\,\sin(\pi t)$ & Modulación global \\
\hline
\end{tabular}
\end{table}

El resultado se normaliza y comprime con factor 0.85 para suavizar transiciones y evitar cambios abruptos.

\subsection{Niveles Discretos de Carga}

Los valores continuos de \(C(t)\), que oscilan aproximadamente en \([-1.8, 1.8]\), se mapean a doce niveles discretos de carga. Cada nivel se asocia con un valor en Erlangs.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{capitulos/img/SIMULACION_DISTRIBUCION_NIVELES DE CARGA.png}
    \caption{Distribución de niveles de carga en la simulación}
    \label{fig:SIMULACION_DISTRIBUCION_NIVELES}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{capitulos/img/SIMULACION_EVOLUCION_TEMPORAL_DE_LA_CARGA.png}
    \caption{Evolución temporal de la carga}
    \label{fig:SIMULACION_EVOLUCION_TEMPORAL}
\end{figure}

El patrón resultante presenta aproximadamente tres ciclos principales durante la simulación, con los siguientes rangos característicos de carga:

\begin{itemize}
    \item \textbf{Valores mínimos:} 1000--1600 Erlangs
    \item \textbf{Zonas medias:} 2300--2700 Erlangs
    \item \textbf{Picos máximos:} 3300--3750 Erlangs
\end{itemize}

\subsection{Identificación de Fases Operativas} 

Para cada instante de simulación se identifica la fase operativa del sistema basándose en la tendencia local de la carga (derivada aproximada por diferencias finitas). La Tabla~\ref{tab:fases_operativas} describe las fases identificadas:

\begin{table}[H]
\centering
\caption{Fases operativas del sistema basadas en tendencia de carga}
\label{tab:fases_operativas}
\begin{tabular}{lp{10cm}}
\hline
\textbf{Fase} & \textbf{Descripción} \\
\hline
Incremento de carga & El valor de Erlangs aumenta progresivamente \\
Período de alta demanda & Máximo local de carga en la red \\
Decremento de carga & La carga disminuye gradualmente \\
Período de baja demanda & Mínimo local de carga en la red \\
Estado estacionario & Variaciones menores entre instantes consecutivos \\
Fase transitoria & Cambios moderados sin alcanzar extremos \\
\hline
\end{tabular}
\end{table}

Esta clasificación enriquece los datos sintéticos con información contextual sobre la dinámica del tráfico.

\section{Herramientas de Implementación}

Se utilizó el ecosistema \textbf{Scikit-learn}~\cite{pedregosa2011scikit} en Python para todo el proceso de Machine Learning. Esta biblioteca proporciona algoritmos de aprendizaje supervisado optimizados junto con herramientas para preprocesamiento, validación y evaluación de modelos.

Bibliotecas complementarias utilizadas:
\begin{itemize}
    \item \textbf{Pandas:} Manipulación de datos tabulares
    \item \textbf{NumPy:} Operaciones numéricas eficientes
    \item \textbf{Matplotlib/Seaborn:} Visualización de resultados
    \item \textbf{Flask:} Framework web para implementación de APIs REST
    \item \textbf{Waitress:} Servidor WSGI para producción
    \item \textbf{Joblib:} Serialización de modelos entrenados
\end{itemize}

Para el escalamiento de características se empleó \textbf{RobustScaler}, que utiliza la mediana y el rango intercuartílico en lugar de media y desviación estándar, haciéndolo robusto ante valores atípicos presentes en métricas de redes ópticas.

\section{Arquitectura del Sistema de Predicción}

El sistema implementa dos modelos de clasificación independientes, cada uno entrenado para detectar cuándo el BFR futuro superará su umbral correspondiente:

\subsection{Modelo para Umbral Mínimo (BFR = 0.20)}

Este modelo predice si la red superará el estado de fragmentación inicial, determinando si es necesario activar la desfragmentación. Opera con un umbral de decisión optimizado en 0.55, balanceando adecuadamente precisión y cobertura.

\subsection{Modelo para Umbral Crítico (BFR = 0.46)}

Este modelo identifica situaciones críticas que requieren desfragmentación intensiva. Su activación indica que la red alcanzará niveles de fragmentación que incrementan significativamente la probabilidad de bloqueo. Utiliza un umbral de decisión de 0.70 para priorizar precisión y minimizar falsas alarmas.

Ambos modelos utilizan \textbf{Gradient Boosting Classifier}~\cite{friedman2001greedy}, implementado en Scikit-learn~\cite{pedregosa2011scikit}, con la siguiente configuración optimizada:

\begin{itemize}
    \item \textbf{n\_estimators:} 150 árboles secuenciales
    \item \textbf{learning\_rate:} 0.05 (tasa de aprendizaje conservadora)
    \item \textbf{max\_depth:} 5 niveles máximos de profundidad
    \item \textbf{min\_samples\_split:} 25 muestras mínimas para dividir un nodo
    \item \textbf{min\_samples\_leaf:} 12 muestras mínimas por hoja
    \item \textbf{subsample:} 0.8 (Stochastic Gradient Boosting)
    \item \textbf{class\_weight:} 'balanced' (manejo de desbalance de clases)
    \item \textbf{random\_state:} 42 (reproducibilidad)
\end{itemize}

Gradient Boosting construye árboles de decisión de forma secuencial, donde cada árbol corrige los errores del anterior mediante minimización de la función de pérdida (log loss) por descenso de gradiente~\cite{friedman2001greedy}. La tasa de aprendizaje baja combinada con 150 estimadores permite un aprendizaje gradual y robusto, reduciendo el riesgo de sobreajuste.

\section{Proceso de Entrenamiento}

\subsection{División Estratificada de Datos}

Se implementó una división estratificada en tres conjuntos, garantizando que cada uno mantenga la misma proporción de clases que el dataset original:

\begin{itemize}
    \item \textbf{Entrenamiento:} 70\% de los datos (279,299 muestras)
    \item \textbf{Validación:} 15\% de los datos (59,851 muestras)
    \item \textbf{Prueba:} 15\% de los datos (59,850 muestras)
\end{itemize}

Para el umbral crítico (0.46), la distribución fue:
\begin{itemize}
    \item Entrenamiento: 189,374 casos no críticos, 89,925 casos críticos
    \item Validación: 40,581 casos no críticos, 19,270 casos críticos
    \item Prueba: 40,580 casos no críticos, 19,270 casos críticos
\end{itemize}

Para el umbral mínimo (0.20), debido a que la red opera mayormente sobre este umbral, la distribución mostró un desbalance inverso:
\begin{itemize}
    \item Entrenamiento: 8,080 casos bajo umbral, 271,219 casos sobre umbral
    \item Validación: 1,732 casos bajo umbral, 58,119 casos sobre umbral
    \item Prueba: 1,731 casos bajo umbral, 58,119 casos sobre umbral
\end{itemize}

\subsection{Preprocesamiento}

Las características fueron escaladas usando RobustScaler, que normaliza basándose en estadísticos robustos:

\begin{equation}
X_{scaled} = \frac{X - \text{mediana}(X)}{\text{IQR}(X)}
\end{equation}

donde IQR es el rango intercuartílico. El escalador se ajusta únicamente con datos de entrenamiento y se aplica posteriormente a validación y prueba, evitando fuga de información (\textit{data leakage}).

Se utilizaron 11 características en total, todas relacionadas con métricas de fragmentación y utilización de la red, excluyendo las columnas de identificación temporal y las variables objetivo futuras.

\subsection{Entrenamiento Iterativo y Monitoreo}

El entrenamiento se realizó de forma incremental, evaluando modelos intermedios cada 10 árboles (de 10 a 150) y calculando el Log Loss en cada punto:

\begin{equation}
\text{Log Loss} = -\frac{1}{N}\sum_{i=1}^{N}[y_i \log(p_i) + (1-y_i)\log(1-p_i)]
\end{equation}

donde \(p_i\) es la probabilidad predicha y \(y_i\) la clase verdadera.

Se monitoreó el error en entrenamiento y validación para detectar sobreajuste. El análisis de convergencia mostró que:

\begin{enumerate}
    \item Ambos errores decrecen inicialmente, indicando aprendizaje efectivo
    \item El error de validación alcanza un mínimo alrededor de 100 iteraciones
    \item La diferencia entre errores de entrenamiento y validación permanece controlada, confirmando buena capacidad de generalización
\end{enumerate}

\subsection{Optimización de Umbrales de Decisión}

Posterior al entrenamiento, se optimizaron los umbrales de clasificación para cada modelo evaluando puntos entre 0.30 y 0.80 con incrementos de 0.05.

Para el modelo de umbral crítico (0.46), se utilizó la función objetivo:
\begin{equation}
\text{Score} = 0.5 \times F1 + 0.5 \times \text{Precisión}
\end{equation}

El proceso de optimización mostró mejora progresiva del score, alcanzando el máximo en umbral 0.70 con F1=0.900 y Precisión=0.957.

Para el modelo de umbral mínimo (0.20), el umbral óptimo fue 0.55, logrando un balance excepcional entre precisión y cobertura debido a la alta predictibilidad de este umbral.

\section{Resultados de Predicción}

\subsection{Métricas de Evaluación}

Se evaluaron ambos modelos en sus conjuntos de prueba respectivos (59,850 muestras no vistas durante entrenamiento). Las métricas utilizadas para esta clasificación binaria fueron:

\begin{itemize}
    \item \textbf{Precisión} (\textit{Precision}): Porcentaje de predicciones positivas que fueron correctas
    \item \textbf{Recall} (\textit{Sensibilidad}): Porcentaje de casos positivos reales que fueron detectados
    \item \textbf{F1-Score}: Media armónica entre precisión y recall
    \item \textbf{AUC-ROC}: Área bajo la curva ROC, capacidad discriminativa general
\end{itemize}

\subsection{Análisis de Predictibilidad del Horizonte}

Previo al entrenamiento se realizó un análisis exhaustivo de la predictibilidad del horizonte de 1000 demandas. Los resultados sobre 399,000 muestras válidas confirmaron la viabilidad del horizonte seleccionado:

\begin{itemize}
    \item \textbf{Autocorrelación:} 0.976 --- Fuerte correlación entre el BFR actual y el BFR a 1000 demandas futuras
    \item \textbf{Persistencia:} 0.975 --- Más del 97\% de los casos presentan cambios menores al 10\%
    \item \textbf{Volatilidad:} 0.041 --- Variabilidad baja y predecible del índice de fragmentación
    \item \textbf{Score de viabilidad:} 0.879 --- Confirmación cuantitativa de alta viabilidad predictiva
\end{itemize}

Estos indicadores confirman que el horizonte de 1000 demandas presenta estabilidad temporal suficiente para entrenar modelos efectivos de Machine Learning \cite{aibin2018traffic}.

\subsection{Resultados del Modelo de Umbral Crítico (BFR = 0.46)}

El modelo para detectar situaciones críticas se evaluó sobre 59,850 muestras de prueba, de las cuales 19,270 correspondían a casos críticos (32.2\%). La Tabla \ref{tab:resultados_046} presenta las métricas finales obtenidas.

\begin{table}[htbp]
\centering
\caption{Resultados del modelo Gradient Boosting para umbral crítico (BFR = 0.46)}
\label{tab:resultados_046}
\begin{tabular}{lcc}
\hline
\textbf{Métrica} & \textbf{Valor} & \textbf{Interpretación} \\
\hline
Precisión & 0.957 & 95.7\% de alertas críticas son correctas \\
Recall & 0.849 & 84.9\% de situaciones críticas detectadas \\
F1-Score & 0.900 & Balance robusto precisión-cobertura \\
AUC-ROC & 0.986 & Excelente capacidad discriminativa \\
Umbral óptimo & 0.70 & Umbral de decisión de probabilidad \\
\hline
\end{tabular}
\end{table}

El modelo alcanzó un rendimiento excelente, superando ampliamente los criterios establecidos:
\begin{itemize}
    \item Precisión $\geq$ 0.80: Cumple con 0.957 (superando en 19.6\%)
    \item F1-Score $\geq$ 0.40: Cumple con 0.900 (superando en 125\%)
\end{itemize}

La precisión superior al 95\% minimiza significativamente las falsas alarmas, reduciendo desfragmentaciones innecesarias y consumo computacional injustificado. El recall del 84.9\% asegura que la mayoría de situaciones críticas serán detectadas con 1000 demandas de anticipación, permitiendo la activación proactiva de mecanismos de desfragmentación.

\subsection{Resultados del Modelo de Umbral Mínimo (BFR = 0.20)}

El modelo para detectar el umbral mínimo presentó un desbalance de clases pronunciado en el conjunto de prueba: 1,731 casos bajo el umbral (2.9\%) y 58,119 casos sobre el umbral (97.1\%). Este desbalance refleja que la red opera mayormente en estados de fragmentación apreciable. La Tabla \ref{tab:resultados_020} presenta las métricas obtenidas.

\begin{table}[htbp]
\centering
\caption{Resultados del modelo Gradient Boosting para umbral mínimo (BFR = 0.20)}
\label{tab:resultados_020}
\begin{tabular}{lcc}
\hline
\textbf{Métrica} & \textbf{Valor} & \textbf{Interpretación} \\
\hline
Precisión & >0.95 & Mínimos falsos positivos \\
Recall & >0.95 & Alta cobertura de detección \\
F1-Score & >0.95 & Balance óptimo \\
AUC-ROC & >0.95 & Excelente capacidad discriminativa \\
Umbral óptimo & 0.55 & Umbral de decisión de probabilidad \\
\hline
\end{tabular}
\end{table}

El modelo alcanzó métricas bastante altas, con desempeño superior:
\begin{itemize}
    \item Precisión $\geq$ 0.80: Cumple ampliamente
    \item F1-Score $\geq$ 0.40: Cumple ampliamente
\end{itemize}

Estos resultados se explican por la alta predictibilidad intrínseca del horizonte temporal y la clara separabilidad entre los casos bajo y sobre el umbral de 0.20. El desbalance de clases fue manejado efectivamente mediante pesos balanceados en el algoritmo Gradient Boosting.

\subsection{Justificación de Gradient Boosting}

Si bien durante el proceso se evaluaron tres algoritmos (Random Forest, Gradient Boosting y Regresión Logística), se seleccionó Gradient Boosting~\cite{friedman2001greedy} como modelo definitivo para ambos umbrales por las siguientes razones:

\begin{itemize}
    \item \textbf{Balance óptimo:} Logra el mejor equilibrio entre precisión y recall tras optimización de umbral
    \item \textbf{Robustez:} Maneja efectivamente el desbalance de clases mediante aprendizaje secuencial
    \item \textbf{Generalización:} La configuración con subsample=0.8 reduce riesgo de sobreajuste
    \item \textbf{Estabilidad:} Menor varianza en predicciones gracias al ensemble secuencial
\end{itemize}

Para el umbral crítico (0.46), Gradient Boosting superó a Random Forest en precisión (95.7\% vs 89.4\%) y a Regresión Logística en todas las métricas, justificando su selección como modelo de producción.

\subsection{Validación de la Estrategia de Dos Umbrales}

Los resultados obtenidos validan la estrategia de utilizar dos modelos independientes con umbrales diferenciados:

\begin{itemize}
    \item \textbf{Modelo 0.20 (alta cobertura):} Detecta la gran mayoría de casos donde se supera fragmentación mínima, permitiendo activar desfragmentación temprana cuando es necesario
    
    \item \textbf{Modelo 0.46 (alta precisión):} Identifica situaciones críticas con mínimas falsas alarmas, justificando desfragmentación intensiva solo cuando es verdaderamente necesario
    
    \item \textbf{Complementariedad:} La combinación permite tres niveles de actuación claramente diferenciados según la severidad predicha
\end{itemize}

Esta arquitectura dual maximiza la eficiencia del sistema, evitando tanto la sub-utilización (no desfragmentar cuando es necesario) como la sobre-utilización (desfragmentar innecesariamente) de recursos computacionales.

\section{Implementación del Sistema}

\subsection{Arquitectura de Servicios}

Se implementaron dos servicios REST independientes que encapsulan los modelos entrenados, permitiendo su integración con el sistema de gestión de red:

\begin{itemize}
    \item \textbf{Servicio de Umbral Mínimo:} API dedicada al modelo de BFR = 0.20
    \item \textbf{Servicio de Umbral Crítico:} API dedicada al modelo de BFR = 0.46
\end{itemize}

La implementación utiliza Flask como framework web y Waitress como servidor WSGI para producción, garantizando estabilidad y manejo eficiente de múltiples solicitudes concurrentes.

\subsection{Lógica de Control de Desfragmentación}

El sistema de control consulta ambas APIs secuencialmente y determina la estrategia de desfragmentación según la siguiente lógica:

\begin{enumerate}
    \item \textbf{Consulta al servicio de umbral 0.20:}
    \begin{itemize}
        \item Si \texttt{probabilidad\_critica} $< 0.80$: No desfragmentar (BFR futuro bajo umbral mínimo)
        \item Si \texttt{probabilidad\_critica} $\geq 0.80$: Proceder a consultar servicio de umbral 0.46
    \end{itemize}
    
    \item \textbf{Consulta al servicio de umbral 0.46 (solo si paso 1 indica riesgo):}
    \begin{itemize}
        \item Si \texttt{debe\_desfragmentar} = \texttt{false}: Desfragmentación de baja frecuencia (BFR entre 0.20 y 0.46)
        \item Si \texttt{debe\_desfragmentar} = \texttt{true}: Desfragmentación de alta frecuencia (BFR $\geq$ 0.46)
    \end{itemize}
\end{enumerate}

Esta arquitectura permite:
\begin{itemize}
    \item Optimización de recursos: Solo se consulta el segundo servicio cuando existe indicación de riesgo
    \item Mantenimiento independiente: Cada modelo puede actualizarse sin afectar al otro
    \item Escalabilidad: Los servicios pueden ejecutarse en servidores separados
    \item Monitoreo granular: Métricas independientes por cada nivel de predicción
\end{itemize}