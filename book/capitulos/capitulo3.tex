\chapter{Aprendizaje Automático}

El Aprendizaje Automático, conocido en inglés como \textit{Machine Learning}, representa una de las áreas más dinámicas y prometedoras dentro del campo de la inteligencia artificial contemporánea. Se fundamenta en el desarrollo de algoritmos y modelos computacionales capaces de identificar patrones complejos en conjuntos de datos, con el propósito de generar predicciones o tomar decisiones informadas sin necesidad de instrucciones programáticas explícitas para cada escenario específico \cite{mitchell1997machine}.

La esencia del aprendizaje automático radica en su capacidad para mejorar el desempeño de manera iterativa mediante la experiencia acumulada. Mitchell \cite{mitchell1997machine} proporciona una definición operacional particularmente esclarecedora: un sistema computacional manifiesta capacidad de aprendizaje cuando su rendimiento en una tarea determinada T, cuantificado mediante una métrica de desempeño P, experimenta una mejora mensurable como consecuencia de la exposición a una experiencia E. Esta conceptualización establece tres componentes fundamentales que articulan cualquier sistema de aprendizaje automático: la tarea objetivo, la experiencia de aprendizaje y el criterio de evaluación.

Para ilustrar estos conceptos de manera concreta, se puede examinar el caso de los sistemas de filtrado de correo electrónico no deseado. Un filtro de spam ejemplifica de forma paradigmática los principios del aprendizaje automático. El sistema desarrolla progresivamente la capacidad de discriminar entre mensajes legítimos y correo no solicitado mediante el análisis de ejemplos previamente etiquetados por usuarios. Estos conjuntos de datos, denominados conjuntos de entrenamiento, contienen tanto instancias positivas (correos identificados como spam) como negativas (mensajes legítimos), permitiendo al algoritmo extraer características distintivas de cada categoría.

En este contexto específico, la tarea T consiste en la clasificación binaria de nuevos mensajes electrónicos, la experiencia E está constituida por el proceso de entrenamiento con los datos etiquetados, y la métrica de desempeño P puede definirse como la tasa de precisión o \textit{Accuracy}, que cuantifica la proporción de mensajes correctamente clasificados en relación con el total de predicciones realizadas.

\section{Clasificación de sistemas o tipos de aprendizaje automático}

La diversidad de aplicaciones y contextos en los que se implementan sistemas de aprendizaje automático ha propiciado el desarrollo de múltiples paradigmas metodológicos. La clasificación más fundamental de estos enfoques se establece en función del tipo y grado de supervisión disponible durante la fase de entrenamiento \cite{mitchell1997machine}. A continuación, se muestran las tres categorías principales:

\begin{itemize}
    \item \textbf{Aprendizaje supervisado:} Este paradigma constituye el enfoque más ampliamente implementado en aplicaciones prácticas. Se caracteriza por la disponibilidad de un conjunto de entrenamiento que incluye pares de entrada-salida, donde cada instancia de entrada está asociada con su correspondiente etiqueta o \textit{label}, que representa la solución correcta. El objetivo del algoritmo consiste en inferir una función de mapeo que establezca la correspondencia óptima entre el espacio de características de entrada y el conjunto de salidas deseadas, de manera que pueda generalizar efectivamente a instancias no observadas previamente.
    
    El aprendizaje supervisado se subdivide en dos categorías fundamentales según la naturaleza de la variable objetivo:

    \begin{itemize}
        \item \textit{Clasificación:} Se trata de brindar ejemplos de entrenamiento donde cada instancia está asociada con una o múltiples clases predefinidas, a modo de que se pueda realizar el entrenamiento y clasificar nuevas entradas dentro de alguna de las clases existentes. Aplicaciones típicas incluyen el reconocimiento de imágenes, detección de fraudes y análisis de sentimientos.
        
        \item \textit{Predicción:} A diferencia de la clasificación, éste consiste en la predicción de una variable objetivo de naturaleza continua o numérica. El sistema recibe datos de entrenamiento compuestos por vectores de características junto con sus valores objetivos correspondientes, permitiendo al modelo aprender la relación funcional entre sí. Esta capacidad predictiva se aplica posteriormente para estimar valores numéricos de nuevas instancias basándose exclusivamente en sus características de entrada. Aplicaciones típicas comprenden la predicción de precios, estimación de demanda y proyecciones temporales.
    \end{itemize}
    
    \item \textbf{Aprendizaje no supervisado:} Este paradigma aborda escenarios donde los datos de entrenamiento carecen de soluciones deseadas. La ausencia de supervisión directa plantea un desafío metodológico fundamentalmente diferente: el algoritmo debe descubrir estructuras intrínsecas, patrones latentes o relaciones subyacentes en los datos sin guía externa. Las técnicas de aprendizaje no supervisado resultan particularmente valiosas para tareas exploratorias, tales como la segmentación de clientes, detección de anomalías, reducción de dimensionalidad y descubrimiento de asociaciones en grandes volúmenes de datos. Este enfoque refleja una aproximación más cercana a cómo los sistemas biológicos pueden aprender mediante la observación y organización autónoma de información sensorial.
    
    \item \textbf{Aprendizaje por refuerzo:} Este paradigma se distingue por su naturaleza secuencial e interactiva. En lugar de aprender a partir de un conjunto estático de ejemplos, el aprendizaje por refuerzo se fundamenta en la interacción continua de un agente con un entorno dinámico \cite{luo2019leveraging}. El proceso de aprendizaje se articula mediante señales de retroalimentación en forma de recompensas (positivas o negativas) que el agente recibe como consecuencia de sus acciones. El objetivo fundamental consiste en desarrollar una política de comportamiento que maximice la recompensa acumulada a largo plazo.
     Este bucle de retroalimentación continua entre acción, observación y recompensa permite al sistema refinar progresivamente su estrategia mediante exploración y explotación del espacio de estados. Las aplicaciones emblemáticas incluyen sistemas de control robótico, estrategias de juegos, optimización de recursos y vehículos autónomos.
\end{itemize}

Cada uno de estos paradigmas presenta ventajas distintivas y limitaciones inherentes, determinando su idoneidad para contextos específicos. La selección del enfoque apropiado constituye una decisión metodológica crucial que debe considerar tanto la naturaleza del problema como las características de los datos disponibles.

\section{Gradient Boosting}

El Gradient Boosting~\cite{friedman2001greedy} representa uno de los algoritmos de aprendizaje automático supervisado más potentes y efectivos en la actualidad, especialmente para problemas de clasificación y regresión con datos tabulares. Este método se fundamenta en el paradigma de aprendizaje por ensamble, donde múltiples modelos predictivos débiles se combinan secuencialmente para construir un predictor robusto de alto rendimiento mediante principios de optimización matemática y aprendizaje iterativo.

\subsection{Fundamentos del Aprendizaje por Ensamble}

El aprendizaje por ensamble o \textit{Ensemble Learning} constituye una estrategia metodológica que combina las predicciones de múltiples modelos base para obtener un resultado final superior al que produciría cualquier modelo individual. Este enfoque se fundamenta en dos principios estadísticos complementarios:

\begin{itemize}
    \item \textbf{Reducción de varianza:} Mediante la agregación de predicciones de modelos diversos, se reduce la sensibilidad del sistema a fluctuaciones en los datos de entrenamiento, incrementando la estabilidad de las predicciones.
    
    \item \textbf{Reducción de sesgo:} La combinación secuencial de modelos permite corregir sistemáticamente errores persistentes, mejorando la capacidad del sistema para capturar relaciones complejas en los datos.
\end{itemize}

Existen dos estrategias principales en el aprendizaje por ensamble. El \textit{Bagging} o agregación bootstrap entrena múltiples modelos de manera independiente y paralela sobre diferentes subconjuntos de datos, combinando posteriormente sus predicciones mediante votación o promediación. El \textit{Boosting}, por otro lado, entrena modelos de forma secuencial, donde cada nuevo modelo se enfoca en corregir los errores de sus predecesores. El Gradient Boosting~\cite{friedman2001greedy} pertenece a esta segunda categoría, distinguiéndose por su fundamentación matemática rigurosa basada en el descenso del gradiente en el espacio funcional.

\subsection{Algoritmo de Gradient Boosting}

Dado un conjunto de entrenamiento $\{(x_i, y_i)\}_{i=1}^{n}$ donde $x_i$ representa el vector de características y $y_i$ la variable objetivo, el Gradient Boosting~\cite{friedman2001greedy} construye un modelo aditivo mediante la incorporación secuencial de árboles de decisión de profundidad limitada:

\begin{equation}
F_M(x) = \sum_{m=0}^{M} \gamma_m h_m(x)
\end{equation}

donde $h_m(x)$ representa el $m$-ésimo aprendiz débil, $\gamma_m$ es el coeficiente de peso asociado, y $M$ denota el número total de iteraciones.

El procedimiento algorítmico consiste en:

\begin{enumerate}
    \item \textbf{Inicialización:} Se establece un modelo inicial $F_0(x)$, comúnmente una constante que minimiza la función de pérdida sobre el conjunto de entrenamiento completo.
    
    \item \textbf{Iteración secuencial:} Para cada iteración $m = 1, 2, ..., M$:
    \begin{itemize}
        \item Se calculan los pseudo-residuos, representando el gradiente negativo de la función de pérdida respecto a las predicciones actuales:
        \begin{equation}
        r_{im} = -\left[\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\right]_{F(x)=F_{m-1}(x)}
        \end{equation}
        
        \item Se entrena un nuevo aprendiz débil $h_m(x)$ para predecir estos residuos.
        
        \item Se determina el coeficiente óptimo $\gamma_m$ que minimiza la pérdida:
        \begin{equation}
        \gamma_m = \arg\min_{\gamma} \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) + \gamma h_m(x_i))
        \end{equation}
        
        \item Se actualiza el modelo mediante:
        \begin{equation}
        F_m(x) = F_{m-1}(x) + \nu \cdot \gamma_m h_m(x)
        \end{equation}
        donde $\nu$ representa la tasa de aprendizaje, un hiperparámetro que controla la contribución de cada árbol al modelo final.
    \end{itemize}
\end{enumerate}

Este proceso continúa hasta alcanzar el número especificado de árboles $M$ o hasta satisfacer un criterio de convergencia establecido.

\subsection{Gradient Boosting Classifier}

Para problemas de clasificación binaria, el \textit{Gradient Boosting Classifier}~\cite{friedman2001greedy} emplea típicamente la función de pérdida logística:

\begin{equation}
L(y, F(x)) = \log(1 + e^{-2yF(x)})
\end{equation}

donde $y \in \{-1, 1\}$ representa la clase verdadera y $F(x)$ la predicción del modelo. La probabilidad de pertenencia a la clase positiva se obtiene mediante la transformación logística:

\begin{equation}
P(y=1|x) = \frac{1}{1 + e^{-2F(x)}}
\end{equation}

Para problemas multiclase, se extiende el enfoque mediante la estrategia \textit{one-versus-all}, entrenando un modelo separado por cada clase y combinando las predicciones mediante normalización softmax para obtener distribuciones de probabilidad válidas.

\subsection{Configuración e Hiperparámetros}

El rendimiento del \textit{Gradient Boosting Classifier} depende críticamente de la configuración apropiada de sus hiperparámetros, los cuales regulan la complejidad del modelo y previenen el sobreajuste:

\begin{itemize}
    \item \textbf{Número de estimadores (n\_estimators):} Define la cantidad de árboles en el ensamble. Valores elevados incrementan la capacidad expresiva pero aumentan el riesgo de sobreajuste y el costo computacional. Típicamente se emplean valores entre 100 y 1000.
    
    \item \textbf{Tasa de aprendizaje (learning\_rate):} Controla la contribución de cada árbol al modelo final. Valores pequeños (0.01-0.1) requieren más árboles pero generalmente producen mejor generalización. Existe una relación de compromiso entre este parámetro y el número de estimadores.
    
    \item \textbf{Profundidad máxima (max\_depth):} Limita la profundidad de cada árbol individual. Árboles superficiales (3-5 niveles) actúan como aprendices débiles efectivos, mientras que árboles profundos incrementan la complejidad y el riesgo de sobreajuste.
    
    \item \textbf{Mínimo de muestras por división (min\_samples\_split):} Especifica el número mínimo de muestras requeridas para dividir un nodo interno. Valores mayores previenen la creación de divisiones excesivamente específicas.
    
    \item \textbf{Mínimo de muestras por hoja (min\_samples\_leaf):} Define el número mínimo de muestras en los nodos terminales. Este parámetro suaviza el modelo en regiones de baja densidad de datos.
    
    \item \textbf{Submuestreo (subsample):} Fracción de muestras utilizada para entrenar cada árbol. Valores menores a 1.0 introducen aleatorización estocástica, mejorando la diversidad del ensamble y reduciendo el sobreajuste.
\end{itemize}

La selección óptima de estos hiperparámetros requiere típicamente validación cruzada y búsqueda sistemática en el espacio de configuraciones mediante técnicas como \textit{Grid Search} o \textit{Random Search}.

\textbf{Ventajas del algoritmo:}
\begin{itemize} 
    \item Capacidad para modelar relaciones no lineales complejas sin requerir transformaciones explícitas de características
    \item Robustez ante variables de diferentes escalas, eliminando la necesidad de normalización
    \item Manejo natural de variables mixtas (numéricas y categóricas)
    \item Resistencia a \textit{outliers} mediante funciones de pérdida apropiadas
    \item Interpretabilidad mediante análisis de importancia de características
    \item Rendimiento competitivo en conjuntos de datos tabulares estructurados
\end{itemize}

\textbf{Limitaciones:}
\begin{itemize}
    \item Susceptibilidad al sobreajuste con configuraciones inadecuadas de hiperparámetros
    \item Entrenamiento secuencial que limita la paralelización eficiente
    \item Mayor costo computacional comparado con algoritmos más simples
    \item Sensibilidad al desbalance de clases, requiriendo estrategias de ponderación
    \item Rendimiento subóptimo en datos de muy alta dimensionalidad comparado con métodos especializados
\end{itemize}

\subsection{Aplicación en MC-EON}

En el contexto de las redes ópticas elásticas multinúcleo (MC-EON), el \textit{Gradient Boosting Classifier} ha demostrado particular eficacia para tareas de clasificación relacionadas con la gestión dinámica de recursos \cite{choudhury2019recent}. Sus principales aplicaciones incluyen:

La naturaleza tabular de los datos operacionales en MC-EON, implementada mediante la librería Scikit-learn~\cite{pedregosa2011scikit}, hace particularmente adecuado el uso de Gradient Boosting, cuyo rendimiento en este tipo de datos frecuentemente supera a aproximaciones basadas en redes neuronales profundas. Adicionalmente, su capacidad para proporcionar estimaciones de importancia de características facilita la comprensión de los factores más relevantes en las decisiones de gestión, aspecto crítico para la validación de sistemas autónomos en entornos de producción \cite{singh2018machine}.